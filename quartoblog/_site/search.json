[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Tecnología y Sociedad es un taller abierto de sociología, datos y progración basado en desarrollos y experiencias, tanto profesionales como colectivas.\nSobre mi te cuento que nací en la ciudad de Lanús (Provincia de Buenos Aires, Argentina) en 1985, siempre me gustaron las compus y tuve la suerte de tener siempre una cerca desde chico. Estudié Sociología en la UBA, actualmente coordino el NIS, formo parte de un equipo análisis e investigación sobre inteligencia artificial en la UNVM y trabajo con investigador asociado en diversas intituciones públicas y privadas.\nComo sociólogo-científico de datos busco resolver preguntas sociológicas con la técnica contemporánea, combinando los saberes propios de la estadística y la programación con la epistemología y la hermenéutica de las ciencias sociales."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Presión sobre el mercado de trabajo",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{navarro2022,\n  author = {Danielle Navarro and Pedro Damian Orden},\n  title = {Presión Sobre El Mercado de Trabajo},\n  date = {2022-07-07},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDanielle Navarro, and Pedro Damian Orden. 2022. “Presión Sobre El\nMercado de Trabajo.” July 7, 2022."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Un jornal sociológico de datos",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jornal de datos",
    "section": "",
    "text": "codigo\n\n\nanalisis\n\n\nvideo\n\n\ntutorial\n\n\n\n\n\n\n\nPedro Damian Orden\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncodigo\n\n\nanalisis\n\n\ntutorial\n\n\n\n\n\n\n\nLic. Pedro Damian Orden\n\n\nJul 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncodigo\n\n\nanalisis\n\n\nvideo\n\n\ntutorial\n\n\n\n\n\n\n\nPedro Damian Orden\n\n\nJul 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neditorial\n\n\n\n\n\n\n\nPedro Damián Orden\n\n\nJan 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisualizaciones\n\n\ncodigo\n\n\n\n\n\n\n\nPedro Damián Orden\n\n\nJan 9, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/CopyOfwelcome/index.html",
    "href": "posts/CopyOfwelcome/index.html",
    "title": "Adultos mayores e ingresos",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/bienvenide/index.html",
    "href": "posts/bienvenide/index.html",
    "title": "Un jornal sociológico de datos",
    "section": "",
    "text": "Organización\nPara optimizar el acceso a los contenidos del blog, los mismos se organizan por categoría y cuentan con filtro dinámico para buscar temas específicos o palabras clave.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{damianorden2022,\n  author = {Pedro Damian Orden and Pedro Damián Orden},\n  title = {Un Jornal Sociológico de Datos},\n  date = {2022-01-09},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPedro Damian Orden, and Pedro Damián Orden. 2022. “Un Jornal\nSociológico de Datos.” January 9, 2022."
  },
  {
    "objectID": "posts/presion/index.html",
    "href": "posts/presion/index.html",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "",
    "text": "En este documento electrónico preocuraré dar cuenta de una experiencia de integración de lenguajes de programación aplicados al procesamiento de la Encuesta Permanente de Hogares (EPH de INDEC), posible gracias Quarto, un sistema de publicación científica y técnica basado en Pandoc1 que funciona de manera amigable con Rstudio2.\nEn términos prácticos, Quarto nos va a permitir, además de publicar el contenido que estamos leyendo, integrar y ejecutar varios lenguajes de programación (Python, R, SQL, Bash, entre otros) en un mismo script3, sin tener que incurrir en mayores gestiones ni detalles. A los fines expositivos, uilizaremos esta potente prestación de manera aplicada para, por medio de Python y R, procesar la EPH y graficar la presión sobre el mercado de trabajo durante los cuatro trimestres de 2021, para el total de los 31 aglomerados donde reside la población urbana argentina4.\nAl concluir el documento se presenta el video formativo que recupera la experiencia en vivo citada en el marco de un taller abierto."
  },
  {
    "objectID": "posts/mayores/index.html",
    "href": "posts/mayores/index.html",
    "title": "Procesando datos de encuestas en R",
    "section": "",
    "text": "El presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Se procura aquí presentar de manera general una serie de procedimientos asociados al procesamiento de encuestas con R.\nUna versión de este documento fue presentada en un Taller abierto del NIS el 16 de septiembre de 2022 y grabada en vivo para que todos y todas puedan replicar la experiencia código a código.\nLas diapositivas utilizadas en la primera parte del encuentro pueden encontrarse aquí."
  },
  {
    "objectID": "posts/mayores/index.html#marco",
    "href": "posts/mayores/index.html#marco",
    "title": "Adultos mayores e ingresos",
    "section": "Marco",
    "text": "Marco\nEl taller abierto es un espacio de encuentro para conocer y utilizar entre todos y todas herramientas de valor profesional para la ciencias sociales, son llevados adelante por el Núcleo de Innovación Social, con el aval del Colegio de Sociólogos y Sociólogas de la Provincia de Buenos Aires (Ley 10.307), el Consejo de Profesionales en Sociología (Ley 23.553) y la Asociación de Sociólogos de la República Argentina.\nEl presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Se procura aquí presentar de manera general una serie de procedimientos asociados al procesamiento de encuestas con R.\nUna versión de este documento fue presentada en un Taller abierto del NIS el 16 de septiembre de 2022 y grabada en vivo para que todos y todas puedan replicar la experiencia código a código.\n\nlibrary(vembedr)\nembed_url(\"https://www.youtube.com/watch?v=mVqxiFUI6xA&ab_channel=ColegiodeSoci%C3%B3logxsBsAs\") %>%\n  use_align(\"center\")%>%\n  use_bs_responsive()\n\n\n\n\n\n\n\n\nLas diapositivas utilizadas en la primera parte del encuentro pueden encontrarse aquí."
  },
  {
    "objectID": "posts/mayores/index.html#presentación",
    "href": "posts/mayores/index.html#presentación",
    "title": "Adultos mayores e ingresos",
    "section": "Presentación",
    "text": "Presentación\nEl presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Procuraremos aquí presentar de manera general una serie de procedimientos asociados al procesamiento de encuestas con R.\nVeremos aquí:\n\nCarga de datos de un formulario drive y transformación.\nAnálisis preliminar/exploratorio.\nVisualización.\nRecomendaciones profesionales: visual mode (ahora mismo), skimr, esquisser y janitor."
  },
  {
    "objectID": "posts/mayores/index.html#carga-de-datos",
    "href": "posts/mayores/index.html#carga-de-datos",
    "title": "Procesando datos de encuestas en R",
    "section": "Carga de datos",
    "text": "Carga de datos\nLos datos de trabajo pertenecen a una sub-muestra de una encuesta realizada por los Colegios Profesionales de Buenos Aires y el NIS a comienzos de la pandemia, los mismos son 100% anónimos y fueron recabados por medio de un formulario Google.\nComenzamos cargando en R las respuestas de drive (previamente debemos compartirlo como público en la web, en formato csv) y creamos el objeto muestra1.\n\nmuestra1<-read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTbdWYdjYhfvt8quj9A5LpIEhH-sSKwxTsG8lKLLK_E_C5r1tkqFNdQNSAdzXvgthWCrFDn7oiN3-9P/pub?gid=346447959&single=true&output=csv\",encoding = \"UTF-8\")\n\nExploramos con funciones base de R nuestros datos (todavía no estamos usando paquetes).\nIndagamos acerca de la clase de nuestros datos:\n\nclass(muestra1)\n\n[1] \"data.frame\"\n\n\nConsultamos la dimensión del conjunto de datos, filas y columnas:\n\ndim(muestra1)\n\n[1] 627  24\n\n\nY podríamos seguir así, pero no, cargamos el (muy genial) paquete skimr el cual nos ayudará a crear un primer resumen de las características de nuestro set de datos (tengamos presente que para correr un paquete primero hay que instalarlo).\n\n#install.packages(\"skimr\") #lo grisado no se ejecuta\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.1.3\n\nskim(muestra1)\n\n\nData summary\n\n\nName\nmuestra1\n\n\nNumber of rows\n627\n\n\nNumber of columns\n24\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n19\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMarca.temporal\n0\n1\n17\n19\n0\n622\n0\n\n\nX.Estás.haciendo.cuarentena.\n0\n1\n2\n2\n0\n2\n0\n\n\nTe.identificas.como.\n0\n1\n0\n6\n9\n3\n0\n\n\nX.En.qué.provincia.vivís.actualmente.\n0\n1\n0\n31\n9\n18\n0\n\n\nX.Cuál.es.el.máximo.nivel.educativo.que.completaste.\n0\n1\n0\n36\n9\n9\n0\n\n\nX.Cuál.es.tu.principal.ocupación.\n0\n1\n0\n156\n9\n11\n0\n\n\nX.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..\n0\n1\n0\n29\n119\n4\n0\n\n\nX.Tenes.hijos.en.edad.escolar.\n0\n1\n0\n49\n9\n5\n0\n\n\nX.Estás.viviendo.con.ellos.durante.esta.cuarentena.\n0\n1\n0\n68\n310\n4\n0\n\n\nDe.la.siguiente.lista..Cuáles.son.tus.tres.principales.medios.para.informarte.sobre.los.asuntos.del.país.y.la.circunstancia.del.coronavirus.\n0\n1\n0\n151\n9\n246\n0\n\n\nX.Te.gustaría.nombrar.algún.otro.medio.que.estés.usando.\n0\n1\n0\n125\n224\n119\n0\n\n\nX.Cambiaste.la.forma.en.que.te.informas.desde.que.comenzó.la.cuarentena.\n0\n1\n0\n2\n9\n3\n0\n\n\nX.Cómo.cambió.la.forma.en.que.te.informaste\n0\n1\n0\n626\n426\n201\n0\n\n\nX.Recibiste.noticias..información.relacionada.al.coronavirus.y.o.la.cuarentena.que.resultaron.ser.falsas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Recordas.a.través.de.qué.medio.recibiste.esa.información.falsa.\n0\n1\n0\n152\n159\n103\n0\n\n\nX.Crees.que.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Cómo.crees.que.influyen.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n909\n212\n400\n0\n\n\nX.Cuál.es.la.ocupación.de.la.persona.que.realiza.el.principal.aporte.económico.\n0\n1\n0\n167\n9\n11\n0\n\n\nAnte.una.emergencia.médica..problema.de.salud..a.dónde.acudis.primero.\n0\n1\n0\n116\n12\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nX.Cuántos.años.tenés.\n9\n0.99\n42.48\n13.65\n18\n32\n40\n53\n82\n▅▇▅▃▁\n\n\nX.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.\n9\n0.99\n4.28\n0.79\n1\n4\n4\n5\n5\n▁▁▂▆▇\n\n\nX.Cuál.es.tu.opinión.acerca.de.lo.que.comunican.los.medios.de.comunicación.argentinos.sobre.el.Coronavirus.\n9\n0.99\n3.34\n0.89\n1\n3\n3\n4\n5\n▁▂▇▆▂\n\n\nX.Cuántas.personas.viven.en.tu.hogar.incluyéndote.a.vos.\n9\n0.99\n3.54\n20.97\n0\n2\n2\n4\n522\n▇▁▁▁▁\n\n\nX.y.cuántas.realizan.algún.tipo.de.aporte.económico.\n9\n0.99\n1.78\n0.81\n0\n1\n2\n2\n5\n▆▇▂▁▁\n\n\n\n\n\nUn resumen de nuestros datos con dos líneas de código, genial no? Este tipo de paquetes y funciones caracterizan a R, existen muchos desarrollos de la comunidad que pueden ayudarnos en nuestra labor diaria. Lo importante es conocerlos y contar con el criterio de saber en qué momento y cómo usarlos."
  },
  {
    "objectID": "posts/mayores/index.html#limpieza-de-datos",
    "href": "posts/mayores/index.html#limpieza-de-datos",
    "title": "Procesando datos de encuestas en R",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nComo hemos visto, tenemos una muestra de respondentes y la propuesta es ahora presentar algunos cálculos de estadística descriptiva y generar visualizaciones, ya que una parte importante de nuestro trabajo con encuestas tiene que ver con armar gráficos que reflejen el comportamiento de variables.\nAhora bien, antes de avanzar precisamos hacerle algunos ajustes a nuestros datos.\nPara llevar adelante este proceso vamos a cargar dos paquetes muy útiles para transformar datos -tidyverse- ly normalizar las fechas -lubridate-.\n\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"lubridate\")\nlibrary(lubridate)\n\nCreamos el objeto muestra2, son nuestros datos de partida con fechas normalizadas y espacios en blanco reemplazados por NAs (mejora el procesamiento). Lo hacemos mediante las siguientes transformaciones:\n\nmuestra2<-muestra1%>% #pipe de tidyverse\n  mutate(Marca.temporal=sub(\" .*\", \"\", Marca.temporal))%>%\n  #transformamos nuestros datos\n  mutate(Marca.temporal=dmy(Marca.temporal))%>% #formateamos fecha\n  mutate_if(is.character, list(~na_if(.,\"\")))"
  },
  {
    "objectID": "posts/mayores/index.html#primeras-preguntas",
    "href": "posts/mayores/index.html#primeras-preguntas",
    "title": "Procesando datos de encuestas en R",
    "section": "Primeras preguntas",
    "text": "Primeras preguntas\nDado el ajuste rápido de nuestros datos, queremos conocer más sobre el proceso de campo del formulario, por ejemplo: entre qué fechas tuvo lugar y cuántos respondentes tuvo por día?\nVeamos qué podemos decir con nuestro objeto muestra2:\n\nrespuestas <- muestra2%>%\n  group_by(Marca.temporal)%>% #agrupamos por fecha\n  count() #contamos respuestas por fecha\n\nrespuestas\n\n# A tibble: 25 x 2\n# Groups:   Marca.temporal [25]\n   Marca.temporal     n\n   <date>         <int>\n 1 2020-03-31         2\n 2 2020-04-06       367\n 3 2020-04-07       116\n 4 2020-04-08        50\n 5 2020-04-09        23\n 6 2020-04-10        27\n 7 2020-04-11         5\n 8 2020-04-12         2\n 9 2020-04-13         4\n10 2020-04-14         3\n# ... with 15 more rows\n\n\nGraficamos las respuestas por día con ggplot2, una librería R que sirve para hacer gráficos. Viene con el paquete tidyverse que ya tenemos activado.\nVeamos como opera la lógica de estos gráficos en la práctica:\n\nrespuestas%>% #nuestro objeto\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #idicamos las variables a graficar\n  geom_line(size = 0.5) #una geometria que la exprese, en este caso es una linea\n\n\n\n\nVemos que el momento de nuestro campo tuvo un período de actividad desde finales de marzo y durante todo abril, luego registró respuestas esporádicas (por error).\nRepitamos el ejercicio poniendo nuestra atención en el lapso temporal en el que se registró la mayor cantidad de respuestas basándonos en la referencia visual que creamos.\n\nrespuestas%>%\n  filter(!Marca.temporal>=\"2020-05-01\")%>% #excluimos mayo 2020 en adelante\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #una geometria que la exprese, en este caso es una linea\n  geom_line(size = 0.9) #aumentamos la linea\n\n\n\n\nPresentamos ahora una tecnología facilitadora del proceso que acabamos de realizar."
  },
  {
    "objectID": "posts/mayores/index.html#gráficos-con-la-librería-esquisse",
    "href": "posts/mayores/index.html#gráficos-con-la-librería-esquisse",
    "title": "Procesando datos de encuestas en R",
    "section": "Gráficos con la librería Esquisse",
    "text": "Gráficos con la librería Esquisse\nAntes de contarles qué hace, veamos cómo funciona:\n\n#install.packages(\"esquisse\")\nlibrary(esquisse)\n# grisamos nuestro codigo como un machete.\n# lo a ctivamos para consulta \n# respuestas%>%\n#   esquisser()\n\nEsquisse ayuda a explorar y visualizar nuestros datos de forma interactiva. El paquete crea gráficos ggplot de manera ágil por medio de una interfaz basada en arrastrar, soltar y filtrar para luego exportar los resultados como .png, .jpg o recuperar el código.\nPlantea dos utilidades principales:\n\nEDA al instante: aunque ggplot es muy rápido y fácil de usar, esquisse permite explorar visualmente los datos en todos los ángulos con una variedad de tipos de gráficos, filtros, agrupaciones, etc.\nConocer ggplot : con este paquete se puede crear rápidamente un gráfico, mirar el código, hacer un cambio, ver cómo eso impactó en el código y repetir.\n\nComo se distribuye la variable edad de nuestra muestra? lo exploramos con esquisse.\n\n# muestra2%>%\n#   esquisser()\n\n# Cod: ejemplo\n  ggplot(muestra2) +\n  aes(x = X.Cuántos.años.tenés.) +\n  geom_histogram(bins = 10L, fill = \"#46337E\") +\n  labs(\n    x = \"años\",\n    y = \"n respondentes\",\n    title = \"Distribucion de la variable edad\",\n    subtitle = \"datos de muestra\"\n  ) +\n  theme_light()\n\nWarning: Removed 9 rows containing non-finite values (stat_bin)."
  },
  {
    "objectID": "posts/mayores/index.html#calculemos-porcentuales",
    "href": "posts/mayores/index.html#calculemos-porcentuales",
    "title": "Procesando datos de encuestas en R",
    "section": "Calculemos porcentuales",
    "text": "Calculemos porcentuales\nEl paquete janitor es otro aliado imprescindible ya que suma una una gama extra de funcionalidades a la hora de limpiar datos, entre las más destacables: genera nombres de columnas legibles, elimina columnas y filas vacías y encuentra valores duplicados. Aquí la usaremos para un proceso muy específico que es la creación de tablas de frecuencias y porcentuales.\n\n#install.packages(\"janitor\")\nlibrary(janitor)\n\ncuarentena<-muestra2%>%\n    tabyl(X.Estás.haciendo.cuarentena.)\n\nprint(cuarentena)\n\n X.Estás.haciendo.cuarentena.   n    percent\n                           No   9 0.01435407\n                           Sí 618 0.98564593\n\n\nEl recorte de nuestra muestra indica que casi el 99% estaba haciendo cuarentena al momento de responder el formulario.\nCrucemos ahora estos datos con la variable de tenencia de hijos en edad escolar, para crear una tabla de doble entrada.\n\ncruce <- muestra2 %>%\n  rename(hace_home=X.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..)%>%\n  tabyl(X.Tenes.hijos.en.edad.escolar., \n        hace_home,\n        show_na = FALSE)%>%\n  adorn_percentages(\"row\")\n\ncruce\n\n                    X.Tenes.hijos.en.edad.escolar.        No        Sí\n                                No, no tengo hijos 0.2154472 0.7276423\n                   Sí, tengo hijos en edad escolar 0.2352941 0.6993464\n Sí, tengo hijos pero aún no están en edad escolar 0.3000000 0.7000000\n    Sí, tengo hijos pero ya no tienen edad escolar 0.2323232 0.7373737\n Siempre trabajo desde mi casa\n                    0.05691057\n                    0.06535948\n                    0.00000000\n                    0.03030303\n\n# y si lo esquisiamos (?\n# cruce%>%\n#   esquisser() #que pasa?\n\nAsi como los estamos exportando no podemos graficarlos con ggplot ya que se multiplican las columnas con información. Para evitar que esto pase, un procedimiento habitual es volver a transformar nuestros datos en un par clave-valor.\n\ncruce2 <- cruce%>%\n  gather('hace_home', 'pct', c(2:4))%>% #reune varias columnas para convertirlas en un par clave-valor\n  mutate(pct=round(pct*100, 1))# formateamos porcentaje\n\nhead(cruce2)\n\n                     X.Tenes.hijos.en.edad.escolar. hace_home  pct\n1                                No, no tengo hijos        No 21.5\n2                   Sí, tengo hijos en edad escolar        No 23.5\n3 Sí, tengo hijos pero aún no están en edad escolar        No 30.0\n4    Sí, tengo hijos pero ya no tienen edad escolar        No 23.2\n5                                No, no tengo hijos        Sí 72.8\n6                   Sí, tengo hijos en edad escolar        Sí 69.9\n\n#checkeamos\n# cruce2%>%\n#   esquisser()\n\nCon nuestro datos transformados podríamos generar un gráfico de base similar a este:\n\nggplot(cruce2) +\n aes(x = X.Tenes.hijos.en.edad.escolar., y = pct, fill = hace_home) +\n geom_col() +\n scale_fill_hue(direction = 1) +\n  theme(axis.text.x = element_text(angle = 45))"
  },
  {
    "objectID": "posts/mayores/index.html#procesando-variable-de-escala-likert",
    "href": "posts/mayores/index.html#procesando-variable-de-escala-likert",
    "title": "Procesando datos de encuestas en R",
    "section": "Procesando variable de escala Likert",
    "text": "Procesando variable de escala Likert\nO casi. Transformamos la pregunta: en qué medida te sentís informado a acerca de las medidas de prevención del Coronavirus, con una escala de 1 a 5, donde 1 es nada informado/a y 5 es muy informado/a.\n\nmuestra3<-muestra1%>%\n  rename(informa=X.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.)%>%\n  tabyl(informa, \n        show_na = FALSE)\n\nmuestra3<-muestra3%>%\n  mutate(percent=round(percent*100,1))%>%\n  mutate(informa=case_when(informa==1~\"1 nada informado/a\",\n                           informa==2~\"2 un poco informado/a\",\n                           informa==3~\"3 informado/a\",\n                           informa==4~\"4 bastante informado/a\",\n                           informa==5~\"5 muy informado/a\"))%>%\n  mutate(informa=as.factor(informa))\n\n#repetimos el esquisseo (??\n# muestra3%>%\n#   esquisser()"
  },
  {
    "objectID": "posts/mayores/index.html#ejemplo-monitor-socioeconómico",
    "href": "posts/mayores/index.html#ejemplo-monitor-socioeconómico",
    "title": "Procesando datos de encuestas en R",
    "section": "Ejemplo: monitor socioeconómico",
    "text": "Ejemplo: monitor socioeconómico\nEs un tablero creado completamente en R que extrae los microdatos de la Encuesta Permanente de Hogares (INDEC), los procesa y visualiza de manera dinámica para conocer más sobre la coyuntura e historia reciente del mercado de trabajo y condiciones de vida en Argentina.\nSe trata de un proyecto en progreso del NIS que da cuenta de cómo podemos usar las nuevas herramientas de análisis y programación para automatizar y comunicar nuestro trabajo."
  },
  {
    "objectID": "posts/mayores/index.html#bonus",
    "href": "posts/mayores/index.html#bonus",
    "title": "Procesando datos de encuestas en R",
    "section": "Bonus",
    "text": "Bonus\nLa lógica de visualización no es solo para datos, ubicando puntos en los ejes x e y también podremos dibujar:\n\nseq(-2,2, by = 0.01) %>% \n  expand.grid(x=., y=.) %>% \n  ggplot(aes(x = x^3 - sin(y), y = y^3 - cos(x)))+\n  geom_point(alpha = 0.05, \n             color = \"#5E17EB\", shape = 20, size = 0)+ #https://www.color-hex.com/\n  theme_void()+\n  coord_polar()+\n  labs(subtitle = \"Llegamos al final de esta experiencia, gracias por participar\")\n\n\n\n\nHasta la próxima!"
  },
  {
    "objectID": "posts/mayores/te/taller.html",
    "href": "posts/mayores/te/taller.html",
    "title": "Taller abierto",
    "section": "",
    "text": "El taller abierto es un espacio de encuentro para conocer y utilizar entre todos y todas herramientas de valor profesional para la ciencias sociales, son llevados adelante por el Núcleo de Innovación Social, con el aval del Colegio de Sociólogos y Sociólogas de la Provincia de Buenos Aires (Ley 10.307), el Consejo de Profesionales en Sociología (Ley 23.553) y la Asociación de Sociólogos de la República Argentina."
  },
  {
    "objectID": "posts/mayores/te/taller.html#presentación",
    "href": "posts/mayores/te/taller.html#presentación",
    "title": "Taller abierto",
    "section": "Presentación",
    "text": "Presentación\nEl presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Procuraremos aquí presentar de manera general una serie de procedimientos asociados al procesamiento de encuestas con R.\nVeremos aquí:\n\nCarga de datos de un formulario drive y transformación.\nAnálisis preliminar/exploratorio.\nVisualización.\nRecomendaciones profesionales: visual mode (ahora mismo), skimr, esquisser y janitor."
  },
  {
    "objectID": "posts/mayores/te/taller.html#carga-de-datos",
    "href": "posts/mayores/te/taller.html#carga-de-datos",
    "title": "Taller abierto",
    "section": "Carga de datos",
    "text": "Carga de datos\nLos datos de trabajo pertenecen a una sub-muestra de una encuesta realizada por los Colegios Profesionales de Buenos Aires y el NIS a comienzos de la pandemia, los mismos son 100% anónimos y fueron recabados por medio de un formulario Google.\nComenzamos cargando en R las respuestas de drive (previamente debemos compartirlo como público en la web, en formato csv) y creamos el objeto muestra1.\n\nmuestra1<-read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTbdWYdjYhfvt8quj9A5LpIEhH-sSKwxTsG8lKLLK_E_C5r1tkqFNdQNSAdzXvgthWCrFDn7oiN3-9P/pub?gid=346447959&single=true&output=csv\",encoding = \"UTF-8\")\n\nExploramos con funciones base de R nuestros datos (todavía no estamos usando paquetes).\nIndagamos acerca de la clase de nuestros datos:\n\nclass(muestra1)\n\n[1] \"data.frame\"\n\n\nConsultamos la dimensión del conjunto de datos, filas y columnas:\n\ndim(muestra1)\n\n[1] 627  24\n\n\nY podríamos seguir así, pero no, cargamos el (muy genial) paquete skimr el cual nos ayudará a crear un primer resumen de las características de nuestro set de datos (tengamos presente que para correr un paquete primero hay que instalarlo).\n\n#install.packages(\"skimr\") #lo grisado no se ejecuta\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.1.3\n\nskim(muestra1)\n\n\nData summary\n\n\nName\nmuestra1\n\n\nNumber of rows\n627\n\n\nNumber of columns\n24\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n19\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMarca.temporal\n0\n1\n17\n19\n0\n622\n0\n\n\nX.Estás.haciendo.cuarentena.\n0\n1\n2\n2\n0\n2\n0\n\n\nTe.identificas.como.\n0\n1\n0\n6\n9\n3\n0\n\n\nX.En.qué.provincia.vivís.actualmente.\n0\n1\n0\n31\n9\n18\n0\n\n\nX.Cuál.es.el.máximo.nivel.educativo.que.completaste.\n0\n1\n0\n36\n9\n9\n0\n\n\nX.Cuál.es.tu.principal.ocupación.\n0\n1\n0\n156\n9\n11\n0\n\n\nX.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..\n0\n1\n0\n29\n119\n4\n0\n\n\nX.Tenes.hijos.en.edad.escolar.\n0\n1\n0\n49\n9\n5\n0\n\n\nX.Estás.viviendo.con.ellos.durante.esta.cuarentena.\n0\n1\n0\n68\n310\n4\n0\n\n\nDe.la.siguiente.lista..Cuáles.son.tus.tres.principales.medios.para.informarte.sobre.los.asuntos.del.país.y.la.circunstancia.del.coronavirus.\n0\n1\n0\n151\n9\n246\n0\n\n\nX.Te.gustaría.nombrar.algún.otro.medio.que.estés.usando.\n0\n1\n0\n125\n224\n119\n0\n\n\nX.Cambiaste.la.forma.en.que.te.informas.desde.que.comenzó.la.cuarentena.\n0\n1\n0\n2\n9\n3\n0\n\n\nX.Cómo.cambió.la.forma.en.que.te.informaste\n0\n1\n0\n626\n426\n201\n0\n\n\nX.Recibiste.noticias..información.relacionada.al.coronavirus.y.o.la.cuarentena.que.resultaron.ser.falsas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Recordas.a.través.de.qué.medio.recibiste.esa.información.falsa.\n0\n1\n0\n152\n159\n103\n0\n\n\nX.Crees.que.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Cómo.crees.que.influyen.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n909\n212\n400\n0\n\n\nX.Cuál.es.la.ocupación.de.la.persona.que.realiza.el.principal.aporte.económico.\n0\n1\n0\n167\n9\n11\n0\n\n\nAnte.una.emergencia.médica..problema.de.salud..a.dónde.acudis.primero.\n0\n1\n0\n116\n12\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nX.Cuántos.años.tenés.\n9\n0.99\n42.48\n13.65\n18\n32\n40\n53\n82\n▅▇▅▃▁\n\n\nX.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.\n9\n0.99\n4.28\n0.79\n1\n4\n4\n5\n5\n▁▁▂▆▇\n\n\nX.Cuál.es.tu.opinión.acerca.de.lo.que.comunican.los.medios.de.comunicación.argentinos.sobre.el.Coronavirus.\n9\n0.99\n3.34\n0.89\n1\n3\n3\n4\n5\n▁▂▇▆▂\n\n\nX.Cuántas.personas.viven.en.tu.hogar.incluyéndote.a.vos.\n9\n0.99\n3.54\n20.97\n0\n2\n2\n4\n522\n▇▁▁▁▁\n\n\nX.y.cuántas.realizan.algún.tipo.de.aporte.económico.\n9\n0.99\n1.78\n0.81\n0\n1\n2\n2\n5\n▆▇▂▁▁\n\n\n\n\n\nUn resumen de nuestros datos con dos líneas de código, genial no? Este tipo de paquetes y funciones caracterizan a R, existen muchos desarrollos de la comunidad que pueden ayudarnos en nuestra labor diaria. Lo importante es conocerlos y contar con el criterio de saber en qué momento y cómo usarlos."
  },
  {
    "objectID": "posts/mayores/te/taller.html#limpieza-de-datos",
    "href": "posts/mayores/te/taller.html#limpieza-de-datos",
    "title": "Taller abierto",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nComo hemos visto, tenemos una muestra de respondentes y la propuesta es ahora presentar algunos cálculos de estadística descriptiva y generar visualizaciones, ya que una parte importante de nuestro trabajo con encuestas tiene que ver con armar gráficos que reflejen el comportamiento de variables.\nAhora bien, antes de avanzar precisamos hacerle algunos ajustes a nuestros datos.\nPara llevar adelante este proceso vamos a cargar dos paquetes muy útiles para transformar datos -tidyverse- ly normalizar las fechas -lubridate-.\n\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"lubridate\")\nlibrary(lubridate)\n\nCreamos el objeto muestra2, son nuestros datos de partida con fechas normalizadas y espacios en blanco reemplazados por NAs (mejora el procesamiento). Lo hacemos mediante las siguientes transformaciones:\n\nmuestra2<-muestra1%>% #pipe de tidyverse\n  mutate(Marca.temporal=sub(\" .*\", \"\", Marca.temporal))%>%\n  #transformamos nuestros datos\n  mutate(Marca.temporal=dmy(Marca.temporal))%>% #formateamos fecha\n  mutate_if(is.character, list(~na_if(.,\"\")))"
  },
  {
    "objectID": "posts/mayores/te/taller.html#primeras-preguntas",
    "href": "posts/mayores/te/taller.html#primeras-preguntas",
    "title": "Taller abierto",
    "section": "Primeras preguntas",
    "text": "Primeras preguntas\nDado el ajuste rápido de nuestros datos, queremos conocer más sobre el proceso de campo del formulario, por ejemplo: entre qué fechas tuvo lugar y cuántos respondentes tuvo por día?\nVeamos qué podemos decir con nuestro objeto muestra2:\n\nrespuestas <- muestra2%>%\n  group_by(Marca.temporal)%>% #agrupamos por fecha\n  count() #contamos respuestas por fecha\n\nrespuestas\n\n# A tibble: 25 x 2\n# Groups:   Marca.temporal [25]\n   Marca.temporal     n\n   <date>         <int>\n 1 2020-03-31         2\n 2 2020-04-06       367\n 3 2020-04-07       116\n 4 2020-04-08        50\n 5 2020-04-09        23\n 6 2020-04-10        27\n 7 2020-04-11         5\n 8 2020-04-12         2\n 9 2020-04-13         4\n10 2020-04-14         3\n# ... with 15 more rows\n\n\nGraficamos las respuestas por día con ggplot2, una librería R que sirve para hacer gráficos. Viene con el paquete tidyverse que ya tenemos activado.\nVeamos como opera la lógica de estos gráficos en la práctica:\n\nrespuestas%>% #nuestro objeto\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #idicamos las variables a graficar\n  geom_line(size = 0.5) #una geometria que la exprese, en este caso es una linea\n\n\n\n\nVemos que el momento de nuestro campo tuvo un período de actividad desde finales de marzo y durante todo abril, luego registró respuestas esporádicas (por error).\nRepitamos el ejercicio poniendo nuestra atención en el lapso temporal en el que se registró la mayor cantidad de respuestas basándonos en la referencia visual que creamos.\n\nrespuestas%>%\n  filter(!Marca.temporal>=\"2020-05-01\")%>% #excluimos mayo 2020 en adelante\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #una geometria que la exprese, en este caso es una linea\n  geom_line(size = 0.9) #aumentamos la linea\n\n\n\n\nPresentamos ahora una tecnología facilitadora del proceso que acabamos de realizar."
  },
  {
    "objectID": "posts/mayores/te/taller.html#gráficos-con-la-librería-esquisse",
    "href": "posts/mayores/te/taller.html#gráficos-con-la-librería-esquisse",
    "title": "Taller abierto",
    "section": "Gráficos con la librería Esquisse",
    "text": "Gráficos con la librería Esquisse\nAntes de contarles qué hace, veamos cómo funciona:\n\n#install.packages(\"esquisse\")\nlibrary(esquisse)\n# grisamos nuestro codigo como un machete.\n# lo a ctivamos para consulta \n# respuestas%>%\n#   esquisser()\n\nEsquisse ayuda a explorar y visualizar nuestros datos de forma interactiva. El paquete crea gráficos ggplot de manera ágil por medio de una interfaz basada en arrastrar, soltar y filtrar para luego exportar los resultados como .png, .jpg o recuperar el código.\nPlantea dos utilidades principales:\n\nEDA al instante: aunque ggplot es muy rápido y fácil de usar, esquisse permite explorar visualmente los datos en todos los ángulos con una variedad de tipos de gráficos, filtros, agrupaciones, etc.\nConocer ggplot : con este paquete se puede crear rápidamente un gráfico, mirar el código, hacer un cambio, ver cómo eso impactó en el código y repetir.\n\nComo se distribuye la variable edad de nuestra muestra? lo exploramos con esquisse.\n\n# muestra2%>%\n#   esquisser()\n\n# Cod: ejemplo\n  ggplot(muestra2) +\n  aes(x = X.Cuántos.años.tenés.) +\n  geom_histogram(bins = 10L, fill = \"#46337E\") +\n  labs(\n    x = \"años\",\n    y = \"n respondentes\",\n    title = \"Distribucion de la variable edad\",\n    subtitle = \"datos de muestra\"\n  ) +\n  theme_light()\n\nWarning: Removed 9 rows containing non-finite values (stat_bin)."
  },
  {
    "objectID": "posts/mayores/te/taller.html#calculemos-porcentuales",
    "href": "posts/mayores/te/taller.html#calculemos-porcentuales",
    "title": "Taller abierto",
    "section": "Calculemos porcentuales",
    "text": "Calculemos porcentuales\nEl paquete janitor es otro aliado imprescindible ya que suma una una gama extra de funcionalidades a la hora de limpiar datos, entre las más destacables: genera nombres de columnas legibles, elimina columnas y filas vacías y encuentra valores duplicados. Aquí la usaremos para un proceso muy específico que es la creación de tablas de frecuencias y porcentuales.\n\n#install.packages(\"janitor\")\nlibrary(janitor)\n\ncuarentena<-muestra2%>%\n    tabyl(X.Estás.haciendo.cuarentena.)\n\nprint(cuarentena)\n\n X.Estás.haciendo.cuarentena.   n    percent\n                           No   9 0.01435407\n                           Sí 618 0.98564593\n\n\nEl recorte de nuestra muestra indica que casi el 99% estaba haciendo cuarentena al momento de responder el formulario.\nCrucemos ahora estos datos con la variable de tenencia de hijos en edad escolar, para crear una tabla de doble entrada.\n\ncruce <- muestra2 %>%\n  rename(hace_home=X.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..)%>%\n  tabyl(X.Tenes.hijos.en.edad.escolar., \n        hace_home,\n        show_na = FALSE)%>%\n  adorn_percentages(\"row\")\n\ncruce\n\n                    X.Tenes.hijos.en.edad.escolar.        No        Sí\n                                No, no tengo hijos 0.2154472 0.7276423\n                   Sí, tengo hijos en edad escolar 0.2352941 0.6993464\n Sí, tengo hijos pero aún no están en edad escolar 0.3000000 0.7000000\n    Sí, tengo hijos pero ya no tienen edad escolar 0.2323232 0.7373737\n Siempre trabajo desde mi casa\n                    0.05691057\n                    0.06535948\n                    0.00000000\n                    0.03030303\n\n# y si lo esquisiamos (?\n# cruce%>%\n#   esquisser() #que pasa?\n\nAsi como los estamos exportando no podemos graficarlos con ggplot ya que se multiplican las columnas con información. Para evitar que esto pase, un procedimiento habitual es volver a transformar nuestros datos en un par clave-valor.\n\ncruce2 <- cruce%>%\n  gather('hace_home', 'pct', c(2:4))%>% #reune varias columnas para convertirlas en un par clave-valor\n  mutate(pct=round(pct*100, 1))# formateamos porcentaje\n\nhead(cruce2)\n\n                     X.Tenes.hijos.en.edad.escolar. hace_home  pct\n1                                No, no tengo hijos        No 21.5\n2                   Sí, tengo hijos en edad escolar        No 23.5\n3 Sí, tengo hijos pero aún no están en edad escolar        No 30.0\n4    Sí, tengo hijos pero ya no tienen edad escolar        No 23.2\n5                                No, no tengo hijos        Sí 72.8\n6                   Sí, tengo hijos en edad escolar        Sí 69.9\n\n#checkeamos\n# cruce2%>%\n#   esquisser()\n\nCon nuestro datos transformados podríamos generar un gráfico de base similar a este:\n\nggplot(cruce2) +\n aes(x = X.Tenes.hijos.en.edad.escolar., y = pct, fill = hace_home) +\n geom_col() +\n scale_fill_hue(direction = 1) +\n  theme(axis.text.x = element_text(angle = 45))"
  },
  {
    "objectID": "posts/mayores/te/taller.html#procesando-variable-de-escala-likert",
    "href": "posts/mayores/te/taller.html#procesando-variable-de-escala-likert",
    "title": "Taller abierto",
    "section": "Procesando variable de escala Likert",
    "text": "Procesando variable de escala Likert\nO casi. Transformamos la pregunta: en qué medida te sentís informado a acerca de las medidas de prevención del Coronavirus, con una escala de 1 a 5, donde 1 es nada informado/a y 5 es muy informado/a.\n\nmuestra3<-muestra1%>%\n  rename(informa=X.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.)%>%\n  tabyl(informa, \n        show_na = FALSE)\n\nmuestra3<-muestra3%>%\n  mutate(percent=round(percent*100,1))%>%\n  mutate(informa=case_when(informa==1~\"1 nada informado/a\",\n                           informa==2~\"2 un poco informado/a\",\n                           informa==3~\"3 informado/a\",\n                           informa==4~\"4 bastante informado/a\",\n                           informa==5~\"5 muy informado/a\"))%>%\n  mutate(informa=as.factor(informa))\n\n#repetimos el esquisseo (??\n# muestra3%>%\n#   esquisser()"
  },
  {
    "objectID": "posts/mayores/te/taller.html#ejemplo-monitor-socioeconómico",
    "href": "posts/mayores/te/taller.html#ejemplo-monitor-socioeconómico",
    "title": "Taller abierto",
    "section": "Ejemplo: monitor socioeconómico",
    "text": "Ejemplo: monitor socioeconómico\nEs un tablero creado completamente en R que extrae los microdatos de la Encuesta Permanente de Hogares (INDEC), los procesa y visualiza de manera dinámica para conocer más sobre la coyuntura e historia reciente del mercado de trabajo y condiciones de vida en Argentina.\nSe trata de un proyecto en progreso del NIS que da cuenta de cómo podemos usar las nuevas herramientas de análisis y programación para automatizar y comunicar nuestro trabajo."
  },
  {
    "objectID": "posts/mayores/te/taller.html#bonus",
    "href": "posts/mayores/te/taller.html#bonus",
    "title": "Taller abierto",
    "section": "Bonus",
    "text": "Bonus\nLa lógica de visualización no es solo para datos, ubicando puntos en los ejes x e y también podremos dibujar:\n\nseq(-2,2, by = 0.01) %>% \n  expand.grid(x=., y=.) %>% \n  ggplot(aes(x = x^3 - sin(y), y = y^3 - cos(x)))+\n  geom_point(alpha = 0.05, \n             color = \"#5E17EB\", shape = 20, size = 0)+ #https://www.color-hex.com/\n  theme_void()+\n  coord_polar()+\n  labs(subtitle = \"Llegamos al final del taller abierto, gracias por participar\")\n\n\n\n\nHasta la próxima!"
  },
  {
    "objectID": "posts/mayores/index.html#contenidos",
    "href": "posts/mayores/index.html#contenidos",
    "title": "Procesando datos de encuestas en R",
    "section": "Contenidos",
    "text": "Contenidos\nVeremos aquí:\n\nCarga de datos de un formulario drive y transformación.\nAnálisis preliminar/exploratorio.\nVisualización.\nRecomendaciones profesionales: visual mode (ahora mismo), skimr, esquisser y janitor."
  },
  {
    "objectID": "posts/presion/index.html#sobre-el-mercado-de-trabajo",
    "href": "posts/presion/index.html#sobre-el-mercado-de-trabajo",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "Sobre el mercado de trabajo",
    "text": "Sobre el mercado de trabajo\nAl relevar de manera periódica la realidad socioeconómica argentina, la EPH es un gran insumo para conocer los principales indicadores5 sobre el mercado de trabajo y analizar su evolución en el tiempo.\nPara dar con un proceso significativo de la dinámica del mercado laboral, nos enfocaremos en este caso en aquellos grupos de personas que no tienen empleo, están disconformes con el que tienen, o bien desean trabajar más horas, lo que operativamente son reflejados por los “indicadores de presión”6.\nDe esta forma, re-construiremos con datos de la EPH la variable de presión general sobre el mercado de trabajo, para visualisar en nuestro documento cómo un segmento de la PEA puja por mayor participación en el mercado laboral, ya sea demandando trabajar más horas o bien buscando un nuevo empleo7.\nEste caso será una buena y sucinta oportunidad para conocer cómo funciona Quarto y estimular la posibilidad de incorporar e integrar lenguajes para el análisis de datos en las ciencias sociales .\nTomaremos como referencia comparativa con nuestro código los datos que provee el informe técnico / Vol. 6, n° 54: Mercado de trabajo. Tasas eindicadores socioeconómicos (EPH) 8."
  },
  {
    "objectID": "posts/presion/index.html#etl-con-python",
    "href": "posts/presion/index.html#etl-con-python",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "ETL con Python",
    "text": "ETL con Python\nEl trabajo inicial de ETL lo llevaremos adelante en Python9 dado que nos va a resultar más rápido que con R.\nPara la recopilación de microdatos utilizaremos la librería pyeph de reciente lanzamiento y que sus creadores/as presentan de la siguiente forma:\n\n“La librería Pyeph tiene como objetivo facilitar el procesamiento en Python de la Encuesta Permanente de Hogares. Está pensada como un espacio donde se nuclean y centralizan los cálculos vinculados a las mismas para posteriormente ser utilizadas en investigaciones, artículos, publicaciones, etc. Es una librería que hace principal hincapié en la transparencia metodológica utilizando licencias de código abierto y que promueve la colaboración de las comunidades de cientístas de datos, sociales, investigadorxs, desarrolladorxs, periodistas y demás curiosxs”.\n\nVamos entonces a instalar la librería y nos descargaremos el set completo de datos de la encuesta para 2021, no sin antes saber algo importante en Quarto; para construir un bloque de código que ejecute el lenguaje que nos interesa utilizar, primero hay que declararlo.\n\n\nVer código\n#En este caso declaramos un bloque de {python}\n\n#instalamos la libreria de python pyeph\n#!pip install pyeph\n\n#la instalacion esta grisada porque en mi caso la libreria ya está descargada\n\n\nLlamamos a pyeph y descargamos los datos.\n\n\nVer código\nimport pyeph\n\neph1 = pyeph.obtener(data=\"eph\", ano=2021, periodo=1, tipo_base='individual') # EPH individual\n\n\nVer código\neph2 = pyeph.obtener(data=\"eph\", ano=2021, periodo=2, tipo_base='individual') # EPH individual\n\n\nVer código\neph3 = pyeph.obtener(data=\"eph\", ano=2021, periodo=3, tipo_base='individual') # EPH individual\n\n\nVer código\neph4 = pyeph.obtener(data=\"eph\", ano=2021, periodo=4, tipo_base='individual') # EPH individual\n\n\nVer código\neph5 = pyeph.obtener(data=\"eph\", ano=2022, periodo=1, tipo_base='individual') # EPH individual\n\n#eph6 = pyeph.obtener(data=\"eph\", ano=2022, periodo=2, tipo_base='individual') # EPH individual\n\n\nSeguidamente importaremos pandas y formatearemos los datos necesarios para nuestro análisis.\n\n\nVer código\n# !pip install pandas\nimport pandas as pd\n# consturimos nuestro dataframefinal\ndatosehp = pd.concat([eph1, eph2, eph3, eph4, eph5])\n# Nos quedamos con las variables que nos interesan, son 5.\ndatosehp = datosehp[[\"TRIMESTRE\", \"PONDERA\", \"ESTADO\", \"PP03J\", \"PP03H\"]]\n\n#guardamos los datos a un csv\n#datosehp.to_csv('eph2021.csv')"
  },
  {
    "objectID": "posts/presion/index.html#ajustes-y-primeras-visualizaciones-en-r",
    "href": "posts/presion/index.html#ajustes-y-primeras-visualizaciones-en-r",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "Ajustes y primeras visualizaciones en R",
    "text": "Ajustes y primeras visualizaciones en R\nUna vez que llegamos a este punto, vamos a abrir un bloque de código en R para dar forma acabada a nuestro proyecto. Para ello descargamos el archivo csv con los datos que construimos y guardamos más arriba.\n\n\nVer código\neph2021<-read.csv(\"eph2021.csv\")\n\n\nLlamamos a la libería tidyverse para darle la forma final a nuestro dataframe.\n\n\nVer código\nlibrary(tidyverse)\n\n\nAgruparemos los datos por cuatrimestre y les aplicaremos una serie de funciones para identificar ocupados, desocupados, PEA, ocupados demandantes y disponibles. De esta forma podremos también construir las tasas de desocupación abierta, ocupados demandantes, ocupados no demandantes disponibles, ocupados no disponibles y el porcentual resultante de presión sobre el mercado de trabajo.\n\n\nVer código\npresion_ar <- eph2021 %>% \n  group_by(TRIMESTRE) %>% \n  summarise(ocupados = sum(PONDERA[ESTADO == 1]),\n            desocupados = sum(PONDERA[ESTADO == 2]),\n            PEA = ocupados + desocupados,\n            ocupados_demand = sum(PONDERA[ESTADO == 1 & PP03J ==1]),\n            ocupados_disp = sum(PONDERA[ESTADO == 1 & PP03J ==2 & PP03H %in% c(1,2,9)]),\n            `desocupacion abierta` = desocupados/PEA*100,\n            `ocupados demandantes` = ocupados_demand/PEA*100,\n            `ocup. no demandantes disponibles` = ocupados_disp/PEA*100,\n            `ocupados no disponibles` = 100-c(`desocupacion abierta`+`ocupados demandantes`+`ocup. no demandantes disponibles`),\n            `presion sobre el mercado laboral` = `desocupacion abierta`+`ocupados demandantes`+`ocup. no demandantes disponibles`)%>%\n  ungroup()%>%\n  mutate_if(is.numeric, round, digits=2)%>%\n  mutate(\n         TRIMESTRE=as.factor(TRIMESTRE))%>%\n  select(TRIMESTRE,\n         'desocupacion abierta',\n         'ocupados demandantes',\n         'ocup. no demandantes disponibles',\n         'ocupados no disponibles',\n         'presion sobre el mercado laboral')\n\n\nCreemos y visualicemos una tabla con los resultados en gt().\n\n\n\n\n\n  \n    \n      Resumen de tasas seleccionadas de de Mercado de Trabajo\n    \n    \n      Datos porcentuales para los últimos 5 trimestres 2021/2022.\n    \n  \n  \n    \n      Tasas\n      1er trimestre\n      2do trimestre\n      3er trimestre\n      4to trimestre\n    \n  \n  \n    desocupacion abierta\n8.55\n9.60\n8.24\n6.97\n    ocupados demandantes\n16.02\n16.97\n16.47\n17.38\n    ocup. no demandantes disponibles\n5.89\n5.84\n6.67\n6.13\n    ocupados no disponibles\n69.53\n67.59\n68.62\n69.53\n    presion sobre el mercado laboral\n30.47\n32.41\n31.38\n30.47\n  \n  \n    \n      Fuente: elaboracion propia en base a datos de la EPH (INDEC).\n    \n  \n  \n\n\n\n\nGrafiquemos los datos con ggplot2. Primero el desagregado problacional de la PEA que presiona sobre el mercado de trabajo.\n\n\nVer código\n#install.packages(\"glue\")\n\nlibrary(glue) #glue es una libreria util para pegar texto\n\npresion_ar2 <- presion_ar %>%\n    gather('Indicador', 'valor', c(2:6)) %>%\n    arrange(desc(valor))%>%\n    unique()%>%\n    ungroup()\n\ntotal<-presion_ar2%>%\n  filter(Indicador==\"presion sobre el mercado laboral\")\n\np1<-presion_ar2 %>%\n filter(!(Indicador %in% c(\"ocupados no disponibles\", \"presion sobre el mercado laboral\"))) %>%\n ggplot() +\n aes(x = TRIMESTRE, y = valor, fill = Indicador) +\n geom_col(alpha=0.7) +\n scale_fill_manual(values = c(`desocupacion abierta` = \"#F0AF5C\",\n                               `ocup. no demandantes disponibles`='#5C9DF0',\n                               `ocupados demandantes` = \"#1A69D2\"))+\n  geom_label(aes(label = glue(\"{round(valor,digits=1)} %\"), y=valor), \n               size = 3.1, hjust = 0.5, vjust = 1, \n               fontface = \"bold\", colour=\"white\", \n               position = \"stack\", show.legend = FALSE)+\n  geom_text(data = total,\n            aes(x = TRIMESTRE,\n                y = valor,\n                label = paste0(\"Presión total: \\n\", valor, \" %\")),\n            colour=\"#1F4B72\",\n            size = 3,\n            fontface = \"bold\", \n            hjust = 0.5,\n            vjust=-0.1,\n            inherit.aes = FALSE,\n            show.legend = FALSE) +\n  labs(x = \"Trimestre\", \n      y = \"% de la PEA\", \n      title = \"  Grupos de población económicamente activa \nsegún tipo de presión sobre el mercado de trabajo\",\n      subtitle = \"Porcentuales para los 4 trimestres de 2021.\", \n      caption = \"Elaboración propia en base a datos de la EPH INDEC.\", \n      fill = \"tasa:\") +\n  coord_cartesian(ylim = c(0, 50))+\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\np1\n\n\n\n\n\nFinalmente, veamos la película completa, armando un panorama general de cómo es la distribución entre la tasa de ocupados no disponibles y la presión sobre el mercado de trabajo en los 4 trimestres de 2021 para el total de los 31 aglomerados que componen la EPH.\n\n\nVer código\np2 <- presion_ar2 %>%\n  filter((Indicador %in% c(\"ocupados no disponibles\", \n                           \"presion sobre el mercado laboral\"))) %>%\n  ggplot() +\n  aes(x = TRIMESTRE, y = valor, fill = Indicador) +\n  geom_col(position = position_stack(reverse = TRUE), alpha=0.6) +\n  scale_fill_manual(values = c(`ocupados no disponibles` = \"#63C3C5\",\n                               `presion sobre el mercado laboral` = \"#FF8B60\"))+\n  geom_label(aes(label = glue(\"{round(valor,digits=1)} %\"), y=valor), \n               size = 3.1, hjust = 0.5, vjust = 1, \n               fontface = \"bold\", colour=\"white\", \n               position = position_stack(reverse = TRUE), \n             show.legend = FALSE)+\n  labs(x = \"Trimestre\", \n      y = \"% de la PEA\", \n      title = \"Tasa de presión general sobre el mercado de trabajo.\",\n      subtitle = \"Porcentuales para los 4 trimestres de 2021.\", \n      caption = \"Elaboración propia en base a datos de la EPH INDEC.\", \n      fill = \"tasa:\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\np2\n\n\n\n\n\nCon respecto a los datos y objetos gráficos que creamos se prefigura que la presión sobre el mercado de trabajo tendió a reducirse durante el año 2021 lo cual sería a propiori un dato positivo. Esta primera impresión deberá ser analizada en el marco de otros análisis para conocer sus implicancias concretas en la realidad socioeconómica nacional.\nPara acceder a los datos del mercado de trabajo en una serie de tiempo más amplia y en formato interactivo puede consultarse el monitor socioeconómico de mi autoría."
  },
  {
    "objectID": "posts/presion/index.html#conclusiones",
    "href": "posts/presion/index.html#conclusiones",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "Conclusiones:",
    "text": "Conclusiones:\n\nEn Quarto la mezcla no es sinónimo de amontonamiento. La posibilidad amigable de integrar varios lenguajes de progamación en procesos de analítica y modelado de datos en ciencia sociales escala las opciones para hacer y conocer.\nAl respecto se seguirá resaltando que las tecnologías de programación y procesamiento de datos que hoy tenemos a disposición como profesionales10 nos permiten automatizar y/o resolver tareas complejas, reducir tiempos de entrega y costos, hechos que hasta hace poco tiempo resultaban impensables. Es indispensable tomar contacto con la técnica contemporánea, conocer cuales sos sus prestaciones e indagar con criterio profesional el hecho de si pueden o no ayudarnos a resolver problemas de nuestra rutina de trabajo.\nQuarto puede ser pensado mas allá de la plataforma de publicación, como un util secuenciador de nuestros flujos de trabajo, para ordenar fragmentos concretos de nuestro código y articular lenguajes de programación distintos sin tener que perder tiempo en configurar mayores cuestiones.\nAlgo que no es una conclusión pero no he no mencionado anteriormente es que Quarto es muy parecido a Rmarkdown y para quienes vienen usando esta plataforma el pasaje va a ser relativamente sencillo.\nDe la breve experiencia aquí presentada emerge una gran pregunta que tiene que ver con las (nuevas?) formas en que se construyen ciertos saberes contemporáneos. En el campo de las ciencias sociales y el desarrollo computacional la combinación criteriosa de teorías, métodos y lenguajes de programación se prefiguran como una potente estrategia de trabajo para abordar la compleja gama de realidades epocales en las que discurrimos como profesionales."
  },
  {
    "objectID": "posts/presion/index.html#bonus",
    "href": "posts/presion/index.html#bonus",
    "title": "R y Python en Quarto: Explorando la presión sobre el mercado de trabajo según la EPH.",
    "section": "Bonus",
    "text": "Bonus\nEl 22-9-2022 este documento fue presentado en una experiencia de taller abierto del Núcleo de Innovación Social. A continuación el video tutorial que permite seguir la experiencia paso a paso.\n\n\nVer código\nlibrary(vembedr)\nembed_url(\"https://www.youtube.com/watch?v=0SE_XjWJLvA&t=1s\") %>%\n  use_align(\"center\")%>%\n  use_bs_responsive()"
  },
  {
    "objectID": "posts/encuestas/index.html",
    "href": "posts/encuestas/index.html",
    "title": "Procesando datos de encuestas en R",
    "section": "",
    "text": "El presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Se procura aquí presentar de manera general una serie de procedimientos asociados al procesamiento de encuestas con R.\nUna versión de este documento fue presentada en un Taller abierto del NIS el 16 de septiembre de 2022 y grabada en vivo para que todos y todas puedan replicar la experiencia código a código.\nLas diapositivas utilizadas en la primera parte del encuentro pueden encontrarse aquí."
  },
  {
    "objectID": "posts/encuestas/index.html#contenidos",
    "href": "posts/encuestas/index.html#contenidos",
    "title": "Procesando datos de encuestas en R",
    "section": "Contenidos",
    "text": "Contenidos\nVeremos aquí:\n\nCarga de datos de un formulario drive y transformación.\nAnálisis preliminar/exploratorio.\nVisualización.\nRecomendaciones profesionales: visual mode (ahora mismo), skimr, esquisser y janitor."
  },
  {
    "objectID": "posts/encuestas/index.html#carga-de-datos",
    "href": "posts/encuestas/index.html#carga-de-datos",
    "title": "Procesando datos de encuestas en R",
    "section": "Carga de datos",
    "text": "Carga de datos\nLos datos de trabajo pertenecen a una sub-muestra de una encuesta realizada por los Colegios Profesionales de Buenos Aires y el NIS a comienzos de la pandemia, los mismos son 100% anónimos y fueron recabados por medio de un formulario Google.\nComenzamos cargando en R las respuestas de drive (previamente debemos compartirlo como público en la web, en formato csv) y creamos el objeto muestra1.\n\n\nVer código\nmuestra1<-read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTbdWYdjYhfvt8quj9A5LpIEhH-sSKwxTsG8lKLLK_E_C5r1tkqFNdQNSAdzXvgthWCrFDn7oiN3-9P/pub?gid=346447959&single=true&output=csv\",encoding = \"UTF-8\")\n\n\nExploramos con funciones base de R nuestros datos (todavía no estamos usando paquetes).\nIndagamos acerca de la clase de nuestros datos:\n\n\nVer código\nclass(muestra1)\n\n\n[1] \"data.frame\"\n\n\nConsultamos la dimensión del conjunto de datos, filas y columnas:\n\n\nVer código\ndim(muestra1)\n\n\n[1] 627  24\n\n\nY podríamos seguir así, pero no, cargamos el (muy genial) paquete skimr el cual nos ayudará a crear un primer resumen de las características de nuestro set de datos (tengamos presente que para correr un paquete primero hay que instalarlo).\n\n\nVer código\n#install.packages(\"skimr\") #lo grisado no se ejecuta\nlibrary(skimr)\n\n\nWarning: package 'skimr' was built under R version 4.1.3\n\n\nVer código\nskim(muestra1)\n\n\n\nData summary\n\n\nName\nmuestra1\n\n\nNumber of rows\n627\n\n\nNumber of columns\n24\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n19\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMarca.temporal\n0\n1\n17\n19\n0\n622\n0\n\n\nX.Estás.haciendo.cuarentena.\n0\n1\n2\n2\n0\n2\n0\n\n\nTe.identificas.como.\n0\n1\n0\n6\n9\n3\n0\n\n\nX.En.qué.provincia.vivís.actualmente.\n0\n1\n0\n31\n9\n18\n0\n\n\nX.Cuál.es.el.máximo.nivel.educativo.que.completaste.\n0\n1\n0\n36\n9\n9\n0\n\n\nX.Cuál.es.tu.principal.ocupación.\n0\n1\n0\n156\n9\n11\n0\n\n\nX.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..\n0\n1\n0\n29\n119\n4\n0\n\n\nX.Tenes.hijos.en.edad.escolar.\n0\n1\n0\n49\n9\n5\n0\n\n\nX.Estás.viviendo.con.ellos.durante.esta.cuarentena.\n0\n1\n0\n68\n310\n4\n0\n\n\nDe.la.siguiente.lista..Cuáles.son.tus.tres.principales.medios.para.informarte.sobre.los.asuntos.del.país.y.la.circunstancia.del.coronavirus.\n0\n1\n0\n151\n9\n246\n0\n\n\nX.Te.gustaría.nombrar.algún.otro.medio.que.estés.usando.\n0\n1\n0\n125\n224\n119\n0\n\n\nX.Cambiaste.la.forma.en.que.te.informas.desde.que.comenzó.la.cuarentena.\n0\n1\n0\n2\n9\n3\n0\n\n\nX.Cómo.cambió.la.forma.en.que.te.informaste\n0\n1\n0\n626\n426\n201\n0\n\n\nX.Recibiste.noticias..información.relacionada.al.coronavirus.y.o.la.cuarentena.que.resultaron.ser.falsas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Recordas.a.través.de.qué.medio.recibiste.esa.información.falsa.\n0\n1\n0\n152\n159\n103\n0\n\n\nX.Crees.que.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Cómo.crees.que.influyen.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n909\n212\n400\n0\n\n\nX.Cuál.es.la.ocupación.de.la.persona.que.realiza.el.principal.aporte.económico.\n0\n1\n0\n167\n9\n11\n0\n\n\nAnte.una.emergencia.médica..problema.de.salud..a.dónde.acudis.primero.\n0\n1\n0\n116\n12\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nX.Cuántos.años.tenés.\n9\n0.99\n42.48\n13.65\n18\n32\n40\n53\n82\n▅▇▅▃▁\n\n\nX.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.\n9\n0.99\n4.28\n0.79\n1\n4\n4\n5\n5\n▁▁▂▆▇\n\n\nX.Cuál.es.tu.opinión.acerca.de.lo.que.comunican.los.medios.de.comunicación.argentinos.sobre.el.Coronavirus.\n9\n0.99\n3.34\n0.89\n1\n3\n3\n4\n5\n▁▂▇▆▂\n\n\nX.Cuántas.personas.viven.en.tu.hogar.incluyéndote.a.vos.\n9\n0.99\n3.54\n20.97\n0\n2\n2\n4\n522\n▇▁▁▁▁\n\n\nX.y.cuántas.realizan.algún.tipo.de.aporte.económico.\n9\n0.99\n1.78\n0.81\n0\n1\n2\n2\n5\n▆▇▂▁▁\n\n\n\n\n\nUn resumen de nuestros datos con dos líneas de código, genial no? Este tipo de paquetes y funciones caracterizan a R, existen muchos desarrollos de la comunidad que pueden ayudarnos en nuestra labor diaria. Lo importante es conocerlos y contar con el criterio de saber en qué momento y cómo usarlos."
  },
  {
    "objectID": "posts/encuestas/index.html#limpieza-de-datos",
    "href": "posts/encuestas/index.html#limpieza-de-datos",
    "title": "Procesando datos de encuestas en R",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nComo hemos visto, tenemos una muestra de respondentes y la propuesta es ahora presentar algunos cálculos de estadística descriptiva y generar visualizaciones, ya que una parte importante de nuestro trabajo con encuestas tiene que ver con armar gráficos que reflejen el comportamiento de variables.\nAhora bien, antes de avanzar precisamos hacerle algunos ajustes a nuestros datos.\nPara llevar adelante este proceso vamos a cargar dos paquetes muy útiles para transformar datos -tidyverse- ly normalizar las fechas -lubridate-.\n\n\nVer código\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"lubridate\")\nlibrary(lubridate)\n\n\nCreamos el objeto muestra2, son nuestros datos de partida con fechas normalizadas y espacios en blanco reemplazados por NAs (mejora el procesamiento). Lo hacemos mediante las siguientes transformaciones:\n\n\nVer código\nmuestra2<-muestra1%>% #pipe de tidyverse\n  mutate(Marca.temporal=sub(\" .*\", \"\", Marca.temporal))%>%\n  #transformamos nuestros datos\n  mutate(Marca.temporal=dmy(Marca.temporal))%>% #formateamos fecha\n  mutate_if(is.character, list(~na_if(.,\"\")))"
  },
  {
    "objectID": "posts/encuestas/index.html#primeras-preguntas",
    "href": "posts/encuestas/index.html#primeras-preguntas",
    "title": "Procesando datos de encuestas en R",
    "section": "Primeras preguntas",
    "text": "Primeras preguntas\nDado el ajuste rápido de nuestros datos, queremos conocer más sobre el proceso de campo del formulario, por ejemplo: entre qué fechas tuvo lugar y cuántos respondentes tuvo por día?\nVeamos qué podemos decir con nuestro objeto muestra2:\n\n\nVer código\nrespuestas <- muestra2%>%\n  group_by(Marca.temporal)%>% #agrupamos por fecha\n  count() #contamos respuestas por fecha\n\nrespuestas\n\n\n# A tibble: 25 x 2\n# Groups:   Marca.temporal [25]\n   Marca.temporal     n\n   <date>         <int>\n 1 2020-03-31         2\n 2 2020-04-06       367\n 3 2020-04-07       116\n 4 2020-04-08        50\n 5 2020-04-09        23\n 6 2020-04-10        27\n 7 2020-04-11         5\n 8 2020-04-12         2\n 9 2020-04-13         4\n10 2020-04-14         3\n# ... with 15 more rows\n\n\nGraficamos las respuestas por día con ggplot2, una librería R que sirve para hacer gráficos. Viene con el paquete tidyverse que ya tenemos activado.\nVeamos como opera la lógica de estos gráficos en la práctica:\n\n\nVer código\nrespuestas%>% #nuestro objeto\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #idicamos las variables a graficar\n  geom_line(size = 0.5) #una geometria que la exprese, en este caso es una linea\n\n\n\n\n\nVemos que el momento de nuestro campo tuvo un período de actividad desde finales de marzo y durante todo abril, luego registró respuestas esporádicas (por error).\nRepitamos el ejercicio poniendo nuestra atención en el lapso temporal en el que se registró la mayor cantidad de respuestas basándonos en la referencia visual que creamos.\n\n\nVer código\nrespuestas%>%\n  filter(!Marca.temporal>=\"2020-05-01\")%>% #excluimos mayo 2020 en adelante\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #una geometria que la exprese, en este caso es una linea\n  geom_line(size = 0.9) #aumentamos la linea\n\n\n\n\n\nPresentamos ahora una tecnología facilitadora del proceso que acabamos de realizar."
  },
  {
    "objectID": "posts/encuestas/index.html#gráficos-con-la-librería-esquisse",
    "href": "posts/encuestas/index.html#gráficos-con-la-librería-esquisse",
    "title": "Procesando datos de encuestas en R",
    "section": "Gráficos con la librería Esquisse",
    "text": "Gráficos con la librería Esquisse\nAntes de contarles qué hace, veamos cómo funciona:\n\n\nVer código\n#install.packages(\"esquisse\")\nlibrary(esquisse)\n# grisamos nuestro codigo como un machete.\n# lo a ctivamos para consulta \n# respuestas%>%\n#   esquisser()\n\n\nEsquisse ayuda a explorar y visualizar nuestros datos de forma interactiva. El paquete crea gráficos ggplot de manera ágil por medio de una interfaz basada en arrastrar, soltar y filtrar para luego exportar los resultados como .png, .jpg o recuperar el código.\nPlantea dos utilidades principales:\n\nEDA al instante: aunque ggplot es muy rápido y fácil de usar, esquisse permite explorar visualmente los datos en todos los ángulos con una variedad de tipos de gráficos, filtros, agrupaciones, etc.\nConocer ggplot : con este paquete se puede crear rápidamente un gráfico, mirar el código, hacer un cambio, ver cómo eso impactó en el código y repetir.\n\nComo se distribuye la variable edad de nuestra muestra? lo exploramos con esquisse.\n\n\nVer código\n# muestra2%>%\n#   esquisser()\n\n# Cod: ejemplo\n  ggplot(muestra2) +\n  aes(x = X.Cuántos.años.tenés.) +\n  geom_histogram(bins = 10L, fill = \"#46337E\") +\n  labs(\n    x = \"años\",\n    y = \"n respondentes\",\n    title = \"Distribucion de la variable edad\",\n    subtitle = \"datos de muestra\"\n  ) +\n  theme_light()\n\n\nWarning: Removed 9 rows containing non-finite values (stat_bin)."
  },
  {
    "objectID": "posts/encuestas/index.html#calculemos-porcentuales",
    "href": "posts/encuestas/index.html#calculemos-porcentuales",
    "title": "Procesando datos de encuestas en R",
    "section": "Calculemos porcentuales",
    "text": "Calculemos porcentuales\nEl paquete janitor es otro aliado imprescindible ya que suma una una gama extra de funcionalidades a la hora de limpiar datos, entre las más destacables: genera nombres de columnas legibles, elimina columnas y filas vacías y encuentra valores duplicados. Aquí la usaremos para un proceso muy específico que es la creación de tablas de frecuencias y porcentuales.\n\n\nVer código\n#install.packages(\"janitor\")\nlibrary(janitor)\n\ncuarentena<-muestra2%>%\n    tabyl(X.Estás.haciendo.cuarentena.)\n\nprint(cuarentena)\n\n\n X.Estás.haciendo.cuarentena.   n    percent\n                           No   9 0.01435407\n                           Sí 618 0.98564593\n\n\nEl recorte de nuestra muestra indica que casi el 99% estaba haciendo cuarentena al momento de responder el formulario.\nCrucemos ahora estos datos con la variable de tenencia de hijos en edad escolar, para crear una tabla de doble entrada.\n\n\nVer código\ncruce <- muestra2 %>%\n  rename(hace_home=X.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..)%>%\n  tabyl(X.Tenes.hijos.en.edad.escolar., \n        hace_home,\n        show_na = FALSE)%>%\n  adorn_percentages(\"row\")\n\ncruce\n\n\n                    X.Tenes.hijos.en.edad.escolar.        No        Sí\n                                No, no tengo hijos 0.2154472 0.7276423\n                   Sí, tengo hijos en edad escolar 0.2352941 0.6993464\n Sí, tengo hijos pero aún no están en edad escolar 0.3000000 0.7000000\n    Sí, tengo hijos pero ya no tienen edad escolar 0.2323232 0.7373737\n Siempre trabajo desde mi casa\n                    0.05691057\n                    0.06535948\n                    0.00000000\n                    0.03030303\n\n\nVer código\n# y si lo esquisiamos (?\n# cruce%>%\n#   esquisser() #que pasa?\n\n\nAsi como los estamos exportando no podemos graficarlos con ggplot ya que se multiplican las columnas con información. Para evitar que esto pase, un procedimiento habitual es volver a transformar nuestros datos en un par clave-valor.\n\n\nVer código\ncruce2 <- cruce%>%\n  gather('hace_home', 'pct', c(2:4))%>% #reune varias columnas para convertirlas en un par clave-valor\n  mutate(pct=round(pct*100, 1))# formateamos porcentaje\n\nhead(cruce2)\n\n\n                     X.Tenes.hijos.en.edad.escolar. hace_home  pct\n1                                No, no tengo hijos        No 21.5\n2                   Sí, tengo hijos en edad escolar        No 23.5\n3 Sí, tengo hijos pero aún no están en edad escolar        No 30.0\n4    Sí, tengo hijos pero ya no tienen edad escolar        No 23.2\n5                                No, no tengo hijos        Sí 72.8\n6                   Sí, tengo hijos en edad escolar        Sí 69.9\n\n\nVer código\n#checkeamos\n# cruce2%>%\n#   esquisser()\n\n\nCon nuestro datos transformados podríamos generar un gráfico de base similar a este:\n\n\nVer código\nggplot(cruce2) +\n aes(x = X.Tenes.hijos.en.edad.escolar., y = pct, fill = hace_home) +\n geom_col() +\n scale_fill_hue(direction = 1) +\n  theme(axis.text.x = element_text(angle = 45))"
  },
  {
    "objectID": "posts/encuestas/index.html#procesando-variable-de-escala-likert",
    "href": "posts/encuestas/index.html#procesando-variable-de-escala-likert",
    "title": "Procesando datos de encuestas en R",
    "section": "Procesando variable de escala Likert",
    "text": "Procesando variable de escala Likert\nO casi. Transformamos la pregunta: en qué medida te sentís informado a acerca de las medidas de prevención del Coronavirus, con una escala de 1 a 5, donde 1 es nada informado/a y 5 es muy informado/a.\n\n\nVer código\nmuestra3<-muestra1%>%\n  rename(informa=X.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.)%>%\n  tabyl(informa, \n        show_na = FALSE)\n\nmuestra3<-muestra3%>%\n  mutate(percent=round(percent*100,1))%>%\n  mutate(informa=case_when(informa==1~\"1 nada informado/a\",\n                           informa==2~\"2 un poco informado/a\",\n                           informa==3~\"3 informado/a\",\n                           informa==4~\"4 bastante informado/a\",\n                           informa==5~\"5 muy informado/a\"))%>%\n  mutate(informa=as.factor(informa))\n\n#repetimos el esquisseo (??\n# muestra3%>%\n#   esquisser()"
  },
  {
    "objectID": "posts/encuestas/index.html#ejemplo-monitor-socioeconómico",
    "href": "posts/encuestas/index.html#ejemplo-monitor-socioeconómico",
    "title": "Procesando datos de encuestas en R",
    "section": "Ejemplo: monitor socioeconómico",
    "text": "Ejemplo: monitor socioeconómico\nEs un tablero creado completamente en R que extrae los microdatos de la Encuesta Permanente de Hogares (INDEC), los procesa y visualiza de manera dinámica para conocer más sobre la coyuntura e historia reciente del mercado de trabajo y condiciones de vida en Argentina.\nSe trata de un proyecto en progreso del NIS que da cuenta de cómo podemos usar las nuevas herramientas de análisis y programación para automatizar y comunicar nuestro trabajo."
  },
  {
    "objectID": "posts/encuestas/index.html#bonus",
    "href": "posts/encuestas/index.html#bonus",
    "title": "Procesando datos de encuestas en R",
    "section": "Bonus",
    "text": "Bonus\nLa lógica de visualización no es solo para datos, ubicando puntos en los ejes x e y también podremos dibujar:\n\n\nVer código\nseq(-2,2, by = 0.01) %>% \n  expand.grid(x=., y=.) %>% \n  ggplot(aes(x = x^3 - sin(y), y = y^3 - cos(x)))+\n  geom_point(alpha = 0.05, \n             color = \"#5E17EB\", shape = 20, size = 0)+ #https://www.color-hex.com/\n  theme_void()+\n  coord_polar()+\n  labs(subtitle = \"Llegamos al final de esta experiencia, gracias por participar\")\n\n\n\n\n\nHasta la próxima!"
  },
  {
    "objectID": "posts/abuelos/index.html",
    "href": "posts/abuelos/index.html",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "",
    "text": "La crisis de ingresos, que sobrevino a la pospandemia y al acuerdo de deuda con el Fondo Monetario Internacional, ha tenido un impacto profundo en las condiciones de vida de los argentinos y argentinas1.\nEn el caso de la pobreza, como en otros períodos históricos de crisis social y económica, pasó de ser un problema exclusivo de aquellas personas con dificultades para obtener un puesto de trabajo o en condiciones de marginación social, para alcanzar a otros sectores sociales tradicionalmente incluidos como los ocupados2, siendo incluso muchos de ellos empleados del sector formal de la economía, o bien sectores de jubilados; que aún cobrando un haber previsional, producto del trabajo de su vida, no alcanzan a cubrir sus necesidades básicas esenciales. \nDicho lo cual, la propuesta aquí será explorar la realidad de este segundo grupo, muchas veces invisibilizado: los jubilados, prestando atención en términos de ingreso al colectivo que cobra el haber mínimo y que representa, según ANSES3, aproximadamente el 50% del segmento de pasivos en Argentina. Operativamente, se buscará conocer a lo largo de los últimos 10 años cómo han evolucionado las jubilaciones mínimas en nuestro país, y en qué medida han alcanzado, o no, a cubrir la canasta básica específica calculada por la Defensoría del Pueblo de la Tercera Edad de la Ciudad de Buenos Aires. \nFinalmente se procurará aportar nuevos elementos respecto a una hipotética situación de empobrecimiento sectorial."
  },
  {
    "objectID": "posts/abuelos/index.html#recopilación-de-datos-y-fuentes",
    "href": "posts/abuelos/index.html#recopilación-de-datos-y-fuentes",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Recopilación de datos y fuentes",
    "text": "Recopilación de datos y fuentes\nPara explorar los datos de ingresos de los jubilados se consultará del portal de datos abiertos del Estado Nacional el repositorio del haber mínimo jubilatorio, mensual, en pesos corrientes desde 1971, a cargo de la Subsecretaría de Programación Macroeconómica de la Nación.\nLos valores de costo de vida se analizan en función de la denominada “Canasta De Los Jubilados”, una estimación complementaria a las oficiales, desarrollada por la Defensoría del Pueblo de la Tercera Edad de la Ciudad de Buenos Aires . Los datos fueron recuperados de la web por medio de una técnica simple de escrapeo y se encuentran disponibilizados github.\nPor medio del cruce de ambos conjuntos de datos se pretende aportar nuevas claves para estimar en qué medida el colectivo de adultos mayores que cobra el haber mínimo previsional puede garantizar para sí una canasta adecuada a sus necesidades reales."
  },
  {
    "objectID": "posts/abuelos/index.html#librerías",
    "href": "posts/abuelos/index.html#librerías",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Librerías",
    "text": "Librerías\nPara comenzar se requerirán las librerías tidyverse y lubridate necesarias para los procesamientos que siguen a continuación."
  },
  {
    "objectID": "posts/abuelos/index.html#carga-de-datasets-y-primera-aproximación-a-los-datos",
    "href": "posts/abuelos/index.html#carga-de-datasets-y-primera-aproximación-a-los-datos",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Carga de datasets y primera aproximación a los datos",
    "text": "Carga de datasets y primera aproximación a los datos\nSe cargan los conjuntos de datos jubilación y canasta.\nEn ambos casos se trata de archivos formato csv, levantados en R con la función read.csv().\n\n\nVer código\n#datos de haberes minimos\njubilacion <- read.csv(\"https://infra.datos.gob.ar/catalog/sspm/dataset/58/distribution/58.1/download/haber-minimo-jubilatorio-pesos-corrientes-valores-mensuales-desde-1971.csv\")\n\ncanasta <- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQLhJPkHIQbYhbpeWbE2deg-UTGr0Y1AaFFL8gfUN06d9xez7vIziuVpvq4_FhnHZC1MDclr_fDnz_I/pub?output=csv\")\n\n\nAplicando la función summary() se obtendrá un resumen general de los datasets cargados.\n\n\nVer código\nsummary(jubilacion)\n\n\n indice_tiempo      mensual_pesos_corrientes mensual_pesos    \n Length:621         Min.   :     59          Min.   :    0.0  \n Class :character   1st Qu.:    150          1st Qu.:    0.0  \n Mode  :character   Median :   1000          Median :  150.0  \n                    Mean   : 156329          Mean   : 2228.3  \n                    3rd Qu.:  11528          3rd Qu.:  827.2  \n                    Max.   :7840000          Max.   :50353.0  \n\n\nVer código\njubilacion<-jubilacion%>%\n  select(indice_tiempo, mensual_pesos)\n\n\njubilacion contiene como mencionamos anteriormente los valores históricos del haber mínimo desde 1971 en Argentina . De aquí se seleccionan las columnas indice_tiempo y mensual_pesos, con datos de fecha y valor del haber respectivamente.\n\n\nVer código\nsummary(canasta)\n\n\n indice_tiempo      valor.canasta   \n Length:28          Min.   :  2053  \n Class :character   1st Qu.:  4738  \n Mode  :character   Median : 13651  \n                    Mean   : 26616  \n                    3rd Qu.: 32347  \n                    Max.   :151478  \n\n\nPor su parte el conjunto de datos canasta recupera los valores de la canasta de los jubilados desde 2010 a la fecha se comporne de una variable de tiempo (indice_tiempo) y otra propia de su valorización neta (valor.canasta). Se descarta la variable X."
  },
  {
    "objectID": "posts/abuelos/index.html#transformación-de-datos",
    "href": "posts/abuelos/index.html#transformación-de-datos",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Transformación de datos",
    "text": "Transformación de datos\ncanasta y jubilacion serán combinados vía la función left_join() en un nuevo dataframe llamado datosjub, que contiene las variables originales y crea la variable ncanasta que divide para cada mes el valor de la canasta de los jubilados por el monto mensual de los haberes, generando el dato de cuántas jubilaciones mínimas son necesarias para cubrir el costo de vida real de un jubilado desde 2010 a la fecha.\nSeguidamente se renombran variables por un tema de practicidad y se transforma la columna fecha en formato temporal.\n\n\nVer código\ndatosjub <- canasta%>%\n  left_join(jubilacion, by=\"indice_tiempo\")%>%\n  mutate(ncanasta=valor.canasta/mensual_pesos)%>%\n  rename(fecha=indice_tiempo,\n         canasta=valor.canasta,\n         haber_minimo=mensual_pesos)%>%\n  mutate(fecha=as_date(fecha))\n\n\n\nImportante: la decisión de hacer el join a partir del df canasta (y no del dataset jubilación) tiene que ver con la posibilidad de establecer la línea de tiempo de referencia del análisis a partir de las observaciones parcialmente continuas que supone el proceso de medición de la canasta de los jubilados."
  },
  {
    "objectID": "posts/abuelos/index.html#visualización",
    "href": "posts/abuelos/index.html#visualización",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Visualización",
    "text": "Visualización\nUna primera pregunta que sobrevuela desde el inicio de este trabajo es si efectivamente el haber mínimo logra cubrir el costo de la canasta básica. Lo averiguaremos imprimiendo un gráfico de ggplot2 de las dos curvas en paralelo:\n\n\nVer código\ndatosjub%>%\n  select(fecha,canasta,haber_minimo)%>%\n  gather('variable', 'monto', c(2:3))%>%\n  ggplot(.) +\n  aes(x = fecha, y = monto, colour = variable) +\n  geom_line(size = 0.9) +\n  scale_color_manual(values = c(canasta = \"#F8C36D\", \n                                haber_minimo = \"#7DA4E2\")) +\n    scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  labs(title = \"Evolución comparada de la canasta básica de los jubilados\ny del haber mínimo previsional entre 2010 y 2022.\", \n       subtitle = \"Por año y mes de medición de la canasta.\", \n       x = \"Fecha\", y = \"Monto en pesos\", \n       caption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\", \ncolor = \"Variable\") +\n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, size = 8))+\n  theme(legend.position = \"bottom\")\n\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\n\n\n\nObservaremos que desde que comenzó a medirse la canasta de los jubilados en 2010, ésta siempre se mantuvo en ascenso y los haberes mínimos previsionales jamás llegaron a cubrirla.\nCon respecto a la cantidad de jubilaciones mínimas necesarias para alcanzar el costo de la canasta se verá lo siguiente:\n\n\nVer código\nggplot(datosjub) +\n  aes(x = fecha, y = ncanasta) +\n  geom_line(size = 1.1, colour = \"gold\")+\n  geom_point(size = 3, colour = \"red\", alpha=0.2) +\n  scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  labs(title = \"Cantidad de haberes mínimos necesarios para cubrir\nla canasta básica del jubilado.\", \n       subtitle = \"Período 2010-2022\", \n       x = \"Fecha\", \n       y = \"Cantidad de haberes mínimos\", \ncaption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\")+  theme_light()+\n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nSegún lo indica la gráfica, para el período de análisis, se han requerido no menos de dos haberes mínimos para empatar los valores de la canasta básica.\nSe generará para finalizar un último dato, relativo a la brecha porcentual entre canasta y haber mínimo.\n\n\nVer código\ndatosjub%>%\n  mutate(brecha=round(c(canasta-haber_minimo)/canasta*1e2, \n                      digits = 1))%>%\n  ggplot(.) +\n  aes(x = fecha, y = brecha) +\n  geom_line(size = 1.1, colour = \"orange\") +\n  geom_point(size = 3, colour = \"red\", alpha=0.2) +\n  scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  labs(title = \"Brecha entre jubilación mínima y canasta del jubilado\", \n       subtitle = \"Periodo 2010-2020\", \n       x = \"Fecha\", \n       y = \"Brecha %\", \n       caption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\")+ \n  theme_light()+\n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nDesde 2018 la brecha entre jubilaciones mínimas y canasta se mantiene en valores superiores al 60%.\nCuadro de síntesis:\n\n\nVer código\nlibrary(DT)\ndatosjub%>%\n  mutate(brecha=round(c(canasta-haber_minimo)/canasta*1e2, \n                      digits = 1))%>%\n  select(fecha,canasta,haber_minimo,brecha)%>%\n  mutate_if(is.numeric, round, digits=1)%>%\n  datatable(extensions = 'Scroller', options = list(\n    deferRender = TRUE,\n    scrollY = 200,\n    scroller = TRUE\n  ))"
  },
  {
    "objectID": "posts/abuelos/index.html#reflexiones",
    "href": "posts/abuelos/index.html#reflexiones",
    "title": "Situaciones de pobreza por ingreso en adultos mayores con R y Python",
    "section": "Reflexiones",
    "text": "Reflexiones\nA lo largo de este documento se ha recurrido a la potencia técnica de R y Quarto para dar cuenta, en forma exploratoria, de una situación emergente de empobrecimiento progresivo de no menos de la mitad de hombres y mujeres que cobran el haber mínimo jubilatorio en Argentina.\nSi bien es importante destacar que en términos rigurosamente científicos -ya sean econométricos, como sociológicos o estadísticos- es necesario evaluar las mediciones de la canasta utilizada4, el hecho concreto y recientemente medido de que la gran mayoría de jubiladxs que cobra la mínima (la gran mayoría de jubiladxs) no acceda a los bienes y servicios básicos para llevar adelante una vida digna invita a repensar el rol que asignamos como sociedad a nuestro mayores. Rol que en parte puede ser reconstruido analíticamente en base a las políticas de ingreso tomadas para el sector por el Estado Nacional en los últimos 10 años.\nEn un contexto económicamente acuciante como el que vive la Argentina, huelga dar nuevos debates acerca de la eficacia y eficiencia del sistema previsional actual, que en su devenir sume en una situación de pobreza creciente a lxs adultxs mayores, con todos los peligros latentes5 que ello implica para un colectivo que, según cita la bibliografía especializada, ya se encuentra vulnerado6 previamente de maneras múltiples.\n\nBonus:\n\n\nCómo vimos antes podemos correr código de r y python de manera complementaria.\nPor ejemplo, corramos un chunk de python, para que se ejecute tenemos que tenerlo instalado en nuestra PC. Vamos levantar datos de salario mínimo y a compararlos con los de las de los haberes mínimos.\n\n\n\nVer código\n\nimport pandas as pd\n# consturimos nuestro dataframe\n\nurl=\"https://infra.datos.gob.ar/catalog/sspm/dataset/57/distribution/57.1/download/indice-salario-minimo-vital-movil-valores-mensuales-pesos-corrientes-desde-1988.csv\"\n\nc=pd.read_csv(url)\n\n#nos quedamos con dos variables\nsalarios = c[[\"indice_tiempo\", \"salario_minimo_vital_movil_mensual\"]]\n\n#chequeamos nuestros datos\nprint(salarios.head(5))\n\n#guardamos nuestro set en un csv\n\n\n  indice_tiempo  salario_minimo_vital_movil_mensual\n0    1965-01-01                              9800.0\n1    1965-02-01                              9800.0\n2    1965-03-01                              9800.0\n3    1965-04-01                              9800.0\n4    1965-05-01                             11550.0\n\n\nVer código\nsalarios.to_csv('salarios.csv')\n\n\n\nPodemos combinar los datos que descargamos en python con R para crear otras visualizaciones."
  },
  {
    "objectID": "posts/genart/index.html",
    "href": "posts/genart/index.html",
    "title": "Un jornal sociológico de datos",
    "section": "",
    "text": "El arte generativo, también conocido en la actualidad como arte algorítmico, es un tipo de expresión visual que puede ser recreada digitalmente, estableciendo un diálogo difuso entre los campos del arte y la programación.\nA menudo un sentido común extendido asocia el arte al cauce de la expresión emocional de las personas, mientras que el acto de programar es emparentado a fríos códigos y lógicas pragmáticas que conducen a un resultado puntual. El arte generativo, creado por medio de algoritmos, tensa estas creencias siendo ambas cosas y ninguna de ellas. Pondremos aquí en juego herramientas rígidas y lógicas que crean algo asbtracto, impredecible e inesperado.\nEs dable destacar que las bases de la propuesta estética fueron establecidas en el Manifiesto Arte Generativo(https://noticiasrecoleta.com.ar/el-arte-generativo-y-sus-60-anos-exposicion-de-obras-en-el-museo-de-arte-moderno/) por los artistas argentinos Eduardo Mac Entyre y Miguel Ángel Vidal ( foto ) donde se proclamaba el espacio como un campo abierto a las tensiones de formas orbitales, trayectorias proyectadas y planos fugados en profundidad.\n \n\nManos a la obra\nConsidero significativo adentrarse a este tema por su relevancia histórico-cultural, destacando además su dimensión práctica, toda vez que en el proceso de desarrollo de estos objetos, podemos experimentar e involucrarnos con diversas lógicas, formas y colores, una caja de herramientas distinta (pero no tanto) a la que habitualmente utilizamos en nuestra rutina laboral y que nos permite expandir creativamente nuestras habilidades al momento de visualizar fenómenos con R.\n\n\nVer código\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(viridis)\nlibrary(ggplot2)\nlibrary(jasmines)\nlibrary(aRtsy)\nlibrary(generativeart)\n\n\nPara situarnos en el espacio que nos propone R, comenzamos haciendo algo que ya conocemos: un ggplot de puntos en un plano con colores y formas. En términos generales, esta es una de las lógicas subyacentes de la visualización y nos permite tomar una dimensión de las potencialidades de nuestras herramientas.\n\n\nVer código\ndata <- data.frame(a1 = 1:5,# ej\na2 = 1:5)\nggplot(data, aes(a1, a2)) + # ggplot\ngeom_point(col = ifelse(1:nrow(data)==3, \n\"tomato\", \"orange\"),\nshape = ifelse(1:nrow(data)==3,15,16),\nsize = ifelse(1:nrow(data)==3,5,1))\n\n\n\n\n\nCrearemos ahora un espiral de arquímedes para ver qué pasa con ggplot cuando vamos mas allá de las rectas:\n\n\nVer código\n# crea un fondo blanco para el grafico\nopt = theme(legend.position  = \"none\",\npanel.background = element_rect(fill=\"#f0eaf7\"),\naxis.ticks = element_blank(),\npanel.grid = element_blank(),\naxis.title = element_blank(),\naxis.text = element_blank())\n# parametros\na <- 2\nb <- 3\ntheta <- seq(0,50*pi,0.05)\nr <- a + b*theta\ndf <- data.frame(x=r*cos(theta), \ny=r*sin(theta)) #coord\n#objeto ggplot\nggplot(df, aes(x,y)) + \ngeom_path(col='purple') + \nopt\n\n\n\n\n\nLuego de esta sucinta inmersión en la logica de la visualización de elementos, indagaremos en las posibilidades que abren ggplot junto a tres paquetes que complementan las herramientas gráficas disponibles en r, y fueron desarrollados específicamente para la creación ( o producción?) de arte generativo y como veremos nos entregarán resultados más qué interesantes.\n\n\nggplot\n\n\nVer código\npolar_art <- function(seed, n, palette) {\n  \n  # semilla de generacion\n  set.seed(seed)\n  \n  # data frame con valores random de\n  # aesthetics que elegimos\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n)\n  )\n  \n  # grafica segmentos en varios colores, \n  # usando coordenadas polares y una paleta\n  dat |> \n    ggplot(aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) +\n    geom_segment(show.legend = FALSE) +\n    coord_polar() +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_x_continuous(expand = c(0, 0)) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 10)) + \n    theme_void()\n}\n\npolar_art(seed = 1, n = 1000, palette = c(\"#e86af0\", \"#493267\", \"#7bb3ff\"))\n\n\n\n\n\nRepitamos para armar una secuencia con patchwork.\n\n\nVer código\nsample_data <- function(seed = NULL, n = 1000){\n  if(!is.null(seed)) set.seed(seed)\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n),\n    shape = factor(sample(0:22, size = n, replace = TRUE))\n  )\n}\n\npolar_styled_plot <- function(data = NULL, palette) {\n  ggplot(\n    data = data,\n    mapping = aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) + \n    coord_polar(clip = \"off\") +\n    scale_y_continuous(\n      expand = c(0, 0),\n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) +\n    scale_x_continuous(\n      expand = c(0, 0), \n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 5)) + \n    theme_void() + \n    guides(\n      colour = guide_none(),\n      size = guide_none(),\n      fill = guide_none(),\n      shape = guide_none()\n    )\n}\n\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n\ndat <- sample_data(n = 1000, seed = 1) |>\n  mutate(y1 = y0, size = size / 10)\n\np1<-polar_styled_plot(palette = sample_canva(seed = 8)) + \n  geom_segment(data = dat, linetype = \"1111\") \n\n\np2<-polar_styled_plot(palette = sample_canva(seed = 10)) + \n  geom_segment(data = dat, linetype = \"11112266\") \n\n\np3<-polar_styled_plot(palette = sample_canva(seed = 500)) + \n  geom_segment(data = dat, linetype = \"15\") \n\nlibrary(patchwork)\n\n\nWarning: package 'patchwork' was built under R version 4.1.3\n\n\nVer código\np1+p2+p3\n\n\n\n\n\n\n\nJasmines\nCon Jasmines podemos modificar creativamente objetos ggplot a partir de múltiples funciones. En este paquete nuestra visualización parte de una semilla (seed) y desde allí se crea un objeto que puede ser modificado en renderizado, forma, tamaño y otros aspectos de personalizables.\n\n\nVer código\n\n# use_seed(1000) %>% #(objeto inicial, \n# #marco de aletoriedad)\n# entity_circle(grain = 1000, \n# size = 3)%>%\n# #circulo, \n# #diametro, \n# #renderizado de 1000 pts.\n# unfold_warp(iterations = 100) %>% \n# # iteracions (+ \"complejidad\")\n# style_ribbon(palette = \"magma\") \n# #convierte en ggplot\n\n\nAvanzamos en la proyección de una figura mas compleja:\n\n\nVer código\n# use_seed(50) %>%\n# entity_gaussian(grain = 1000, \n# size = 1) %>%\n# unfold_warp(iterations = 100) %>%\n# style_ribbon(\n# palette = \"plasma\", \n# colour = \"ind\", \n# background = \"#00002d\")\n\n\n\n\nflametree\nflametree provee un sistema de funciones y sistemas de trabajo orientados a crear arboles con código y fomentar la experimentación con este tipo de formas expresivas.\n\n\nVer código\nlibrary(flametree)\n\n# elegimos nuestros colores\nshades <- c(\"#c79dd7\", \"#ef4f91\", \"#c5b9cd\", \"#abb1cf\")\n\n#ef4f91 (239,79,145)\n#c79dd7 (199,157,215)\n#4d1b7b (77,27,123)\n\n# definimos los datos con los que se van a generar los arboles\ndat <- flametree_grow(time = 10, trees = 10)\n\n# graficamos\ndat %>% \n  flametree_plot(\n    background = \"antiquewhite\",\n    palette = shades, \n    style = \"nativeflora\"\n  )\n\n\n\n\n\n\n\ncontouR\n\n\nVer código\nlibrary(contouR)\n\n#set up your data\nsetup = contour_grid(grid_size = 100, point_dist = .25, \n             z_method = \"runif\", z = 10, z_span = 10) %>%\n  contour_shape(radius = 15, \n                x_center = 7, y_center = 9) \n\n# plot your data\ncontour_plot(setup$grid_shape) +\n  ggplot2::xlim(1, 30) +\n  ggplot2::ylim(1, 30)\n\n\n\n\n\nSe parece a un planeta hecho crochet no?\n\n\naRtsy\nSi la broma te dió risa…¿Qué diferencia hay en que luego te enteres que fue creada por un algoritmo?” (Marcus du Sautoy, El código creativo )\nAsí comienza Artsy su blog y nos presenta una serie de funcionalidades para crear nuestro obra generativo de forma simple y al alcance de todos y todas. El paquete proporciona varios algoritmos para crear proyecciones ggplot que incorporan aleatoriedad (según la seed) y, de los 3 que vimos, es mi favorito, con lo cual me gustaría profundizar más en él.\nAntes de comenzar a utilizar este paquete es importante saber que el mismo se organiza en colecciones, cada una genera un tipo de proyección o forma distinta.\nIterative es una colección basada en un sistema de reglas e iteración en base a ellas.\nLa función canvas_strokes() permite, por ejemplo, simular el trazo de un pincel ejecutando un calculo de probablilidad en la que todos los puntos de la proyección tienen la probabilidad de adquirir el color del punto próximo, pero también tienen una pequeña posibilidad de asumir un color distinto.\n\n\nVer código\n#library(aRtsy)\nset.seed(5)\n#colores de la paleta de referencia. \n#https://www.color-hex.com/color-palette/84832\ncanvas_strokes(colors = \nc('#e8d0d9', '#e590a5', \n'#75638b', '#507592',\n'#dac291'), \nneighbors = 1, p = 0.005, \niterations = 10, \n#width = 500, height = 500, \nside = FALSE)\n\n\n\n\n\nLa colección Geometric en cambio implementa algoritmos que dibujan formas geométricas y le aplican colores aleatorios.\nEs el caso de canvas_squares, que utiliza una variedad de cuadrados y rectángulos en lugar de líneas. Funciona cortando repetidamente el lienzo en ubicaciones aleatorias y coloreando el área que crean estos cortes:\n\n\nVer código\nset.seed(6)\ncanvas_squares(colors = c(\n'#fac901', '#ffffff', \n'#225095', '#dd0100'),\ncuts = 50, ratio = 1.458, \n#width = 100, height = 100\n)\n\n\n\n\n\nVer código\n#paleta de referencia\n#https://www.color-hex.com/color-palette/25374\n\n\nTambién resultan atractivas las proyecciones de canvas_ribbons() que mantiene la lógica anterior, pero utiliza cintas y triángulos conectados a través de nodos comunes.\n\n\nVer código\nset.seed(784)\ncanvas_ribbons(colors = \nc('#CC102D', \n'#E88514', '#FFFF28', \n'#7DC62C', '#71C0DE',\n'#634C8A'),\nbackground = '#1c2117', \ntriangle = TRUE)\n\n\n\n\n\nVer código\n# referencia de la paleta \n#  https://www.schemecolor.com/the-dark-\n#  side-of-the-moon-pink-floyd-colors.php\n#  lo intente!\n\n\nFinalmente, la colección Supervised trabaja con funciones de agrupación supervisadas propias del machine learning. Los algoritmos de esta colección funcionan generando puntos de datos aleatorios en un plano bidimensional (con una variable de respuesta continua o categórica). Posteriormente la modelan utilizando el algoritmo de aprendizaje supervisado.\nPara el caso concreto del cuadro de mosaicos que sigue operaremos de fondo con un algoritmo k means:\n\n\nVer código\ncanvas_mosaic(colors = \nc('#fff2df',\n'#d69c42', \n'#77ae80','#4b6294',\n'#852a02'),\n#maxk = 1, \nn = 150,resolution = 1000)\n\n\n\n\n\nVer código\n# paleta de referencia\n# https://www.color-hex.com/color-palette/63466\n\n\n\n\nConclusión\nEsta fue una selección de experiencias y posibilidades experimentando con el denominado arte generativo en R, los códigos abiertos de este post y las referencias citadas invitan a lxs interesadxs a replicar-reconfigurar las imágenes propuestas.\nLas primeras impresiones de quien escribe con respecto al arte generativo es que en tanto técnica expresiva estimula creativamente a indagar y conocer más sobre el procesamiento de imágenes y la proyección de datos en R.\nEn este sentido podremos afirmar que arte generativo es una interesante alternativa para quienes quieran programar recrativamente, explorar las posibilidades de formas, colores y espacios que tenemos a disposición en r, procastinar en horario de trabajo o estudio, crear objetos artísticos (eventualmente venderlos a precio justo, recomiendo indagar en que qué es un nft ), todas las anteriores o ninguna, pero siempre con el mismo sentimiento compartido: el amor al arte.\n\nTítulo de foto de cabecera: Eduardo Mac Entyre, Expansión sobre verde, 1971, acrílico sobre tela, 110 x 150 cm.\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{damianorden2022,\n  author = {Pedro Damian Orden and Pedro Damián Orden},\n  title = {Un Jornal Sociológico de Datos},\n  date = {2022-01-09},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPedro Damian Orden, and Pedro Damián Orden. 2022. “Un Jornal\nSociológico de Datos.” January 9, 2022."
  }
]